{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URLs Phishing Detecting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Building ML models to create a classifier \n",
    "in this part i will build ml models, evaluate tham and choose the most accurate classifier for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load requierd packages for this part\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#load packges for data prepration\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#evaluation packages\n",
    "from sklearn import metrics\n",
    "\n",
    "#plotting packges \n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Prepare the Df to the ML Model\n",
    "\n",
    "1. cheking for nulls and data types (no need for encoding there is no category)\n",
    "2. evaluate the features and drop the features with no effect\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Examine the data, check for nulls and data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the new data with the features\n",
    "full_df = pd.read_csv(r\"C:\\Users\\moshi\\Downloads\\notebooks\\perceptionpoint\\data\\full_data.csv\")\n",
    "url_data= full_df.drop(['url'], axis = 1).copy() #drop the url colmun \n",
    "url_data=url_data.sample(frac=1).reset_index(drop=True) #shuffel \n",
    "url_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for nulls values \n",
    "full_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check features datatypes\n",
    "full_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Feature reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a correlation heatmap to check the efficency of features and correlations between them\n",
    "corr=url_data.corr()\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(corr,annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Machine Learning Classifier And Evaluation\n",
    "in this part i will try and examine 3 different classifiers and evalute each one of tham to choose the best one for this task\n",
    "\n",
    "1. RandomForestClassifier\n",
    "2. XGboost Classifier\n",
    "3. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MachineLearning Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for evaluation\n",
    "\n",
    "# This function print and save the results of the models\n",
    "def printAccuracy(model,y_train,y_test,y_train_pred,y_pred):\n",
    "    print(model,\"Accuracy\")\n",
    "    print(\"Accuracy on training data: {:.4f}\".format(metrics.accuracy_score(y_true = y_train, y_pred = y_train_pred)))\n",
    "    print(\"Accuracy on test data: {:.4f}\".format(metrics.accuracy_score(y_true = y_test, y_pred = y_pred)))\n",
    "    \n",
    "# This function print the result of confusion matrix                       \n",
    "def printConfusionMatrix(y_test,y_pred):\n",
    "    confusion = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print(confusion)\n",
    "    print('')\n",
    "    print('TP =',confusion[1, 1])\n",
    "    print('TN =',confusion[0, 0])\n",
    "    print('FP =',confusion[0, 1])\n",
    "    print('FN =',confusion[1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Scaling and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the features and scale them for the model \n",
    "features =url_data.drop(['label'],axis=1)\n",
    "scaler = StandardScaler()\n",
    "origin_scale_rf=StandardScaler().fit(features.values)\n",
    "\n",
    "X = scaler.fit_transform(features.values)\n",
    "X= X[:url_data.shape[0]]\n",
    "y = url_data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data to train and test using 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for finding the best parameters for the classifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [60, 70, 80, 90],\n",
    "    'max_features': ['auto'],\n",
    "    'min_samples_leaf': [2, 3, 4],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'n_estimators': [100, 144, 300, 600]\n",
    "    }\n",
    "rf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "##grid_search.best_params_ result\n",
    "# 'bootstrap': True,\n",
    "# 'max_depth': 90,\n",
    "# 'max_features': 'auto'\n",
    "# 'min_samples_leaf': 2\n",
    "# 'min_samples_split': 2\n",
    "# 'n_estimators': 144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model=RandomForestClassifier(bootstrap= True,max_depth=90,max_features='auto',min_samples_leaf=2,min_samples_split= 2,n_estimators=144)\n",
    "rf_model.fit(X_train,y_train)#fit the model\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_train_pred = rf_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Evalutaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RendomForestclassifier Accuracy\n",
      "Accuracy on training data: 0.9550\n",
      "Accuracy on test data: 0.9422\n"
     ]
    }
   ],
   "source": [
    "printAccuracy(\"RendomForestclassifier\",y_train,y_test,y_train_pred,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[861  30]\n",
      " [ 74 835]]\n",
      "\n",
      "TP = 835\n",
      "TN = 861\n",
      "FP = 30\n",
      "FN = 74\n"
     ]
    }
   ],
   "source": [
    "printConfusionMatrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 XGboost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(learning_rate=0.4,max_depth=7)\n",
    "xgb_model.fit(X_train, y_train)#fit the model\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "y_train_pred = xgb_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier Accuracy\n",
      "Accuracy on training data: 0.9650\n",
      "Accuracy on test data: 0.9439\n"
     ]
    }
   ],
   "source": [
    "printAccuracy(\"XGBoost Classifier\",y_train,y_test,y_train_pred,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[863  28]\n",
      " [ 73 836]]\n",
      "\n",
      "TP = 836\n",
      "TN = 863\n",
      "FP = 28\n",
      "FN = 73\n"
     ]
    }
   ],
   "source": [
    "printConfusionMatrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 500}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depths=list(range(1,6))#list of depths for check from 1-6 \n",
    "min_samples=list(range(500,15000,1000))#list of samples for check from 10% to 100% \n",
    "param_grid = { 'criterion':['gini','entropy'],'max_depth':depths,'min_samples_split':min_samples}\n",
    "dt_grid=DecisionTreeClassifier()# decision tree model\n",
    "dftree_gscv = GridSearchCV(dt_grid, param_grid, cv=5)#use gridsearch to test all values with 5 folds\n",
    "dftree_gscv.fit(X_train, y_train)\n",
    "    \n",
    "dftree_gscv.best_params_\n",
    "\n",
    "##best parameters from grid are:\n",
    "# {'criterion': 'entropy',\n",
    "#  'max_depth': 5\n",
    "#  'min_samples_split': 500}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(criterion='entropy',max_depth = 5,min_samples_split=500)\n",
    "dt_model.fit(X_train, y_train)# fit the model \n",
    "\n",
    "y_pred = dt_model.predict(X_test)\n",
    "y_train_pred = dt_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Classifier Accuracy\n",
      "Accuracy on training data: 0.8653\n",
      "Accuracy on test data: 0.8689\n"
     ]
    }
   ],
   "source": [
    "printAccuracy(\"DecisionTree Classifier\",y_train,y_test,y_train_pred,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[774 117]\n",
      " [119 790]]\n",
      "\n",
      "TP = 790\n",
      "TN = 774\n",
      "FP = 117\n",
      "FN = 119\n"
     ]
    }
   ],
   "source": [
    "printConfusionMatrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
